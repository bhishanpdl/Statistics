{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Of Contents\n",
    "1. State null and alternative hypotheses\n",
    "2. Set alpha value\n",
    "3. Import relevant libraries\n",
    "4. Import athleisure dataset\n",
    "5. Hypothesis Testing\n",
    "6. 2-Factor ANOVA\n",
    "7. 3-Factor ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. State Null and Alternative Hypotheses\n",
    "\n",
    "$H_{01}$ - All athleisure-related keywords are equal in terms of average search volume.  \n",
    "$H_{A1}$ - Some athleisure-related keywords have greater average search volumes than others.\n",
    "\n",
    "\n",
    "\n",
    "$H_{02}$ - People will be equally likely to search for activewear-related terms in any given month.  \n",
    "$H_{A2}$ - People will be more likely to search for activewear-related terms depending on the month.\n",
    "\n",
    "\n",
    "$H_{03}$ - There will be an equal search volume for activewear-related terms on any platform.  \n",
    "$H_{A3}$ - There will be a greater search volume for activewear-related terms on one particular platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Alpha Value\n",
    "\n",
    "We will reject the null hypothesis when **alpha** < **0.05**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Relevant Libraries\n",
    "\n",
    "We will reject the null hypothesis when **alpha** < **0.05**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Import Athleisure Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "athleisure_df = pd.read_csv('../athleisure.csv')\n",
    "athleisure_df.drop(['Unnamed: 0'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hypothesis Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Test 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there differences between pre-selected keywords?\n",
    "\n",
    "$H_{01}$ - All athleisure-related keywords are equal in terms of average search volume.  \n",
    "$H_{A1}$ - Some athleisure-related keywords have greater average search volumes than others. \n",
    "\n",
    "Mean search volume(keyword 1) = Mean search volume(keyword 2) = Mean search volume(keyword 3) = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(athleisure_df.keyword.unique())\n",
    "values = []\n",
    "\n",
    "for keyword in list(athleisure_df.keyword.unique()):\n",
    "    values.append(list(athleisure_df.loc[athleisure_df.keyword == keyword, 'volume']))\n",
    "    \n",
    "data = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain list of dict keyword references for easy input into anova test parameter\n",
    "for keyword in keys:\n",
    "    text = f\" data['{keyword}'],\"\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of ANOVA test:\n",
      " The F-statistic is: 12.048623344578461\n",
      " The p-value is: 1.3293563590514185e-119\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "# stats f_oneway functions takes the groups as input and returns F and P-value\n",
    "fvalue, pvalue = stats.f_oneway(data['yoga pants'],\n",
    " data['sweatpants'],\n",
    " data['sweatshirt'],\n",
    " data['crew neck'],\n",
    " data['thumb hole'],\n",
    " data['pullover'],\n",
    " data['fleece'],\n",
    " data['joggers'],\n",
    " data['hoodie'],\n",
    " data['hooded'],\n",
    " data['capri'],\n",
    " data['muscle tee'],\n",
    " data['basic tee'],\n",
    " data['sweatband'],\n",
    " data['windbreaker'],\n",
    " data['leggings'],\n",
    " data['tank top'],\n",
    " data['muscle tank'],\n",
    " data['long sleeve'],\n",
    " data['short sleeve'],\n",
    " data['mesh'],\n",
    " data['striped'],\n",
    " data['stripes'],\n",
    " data['3 stripes'],\n",
    " data['stripe'],\n",
    " data['stretch'],\n",
    " data['stretchy'],\n",
    " data['stretchable'],\n",
    " data['flex'],\n",
    " data['flexing'],\n",
    " data['lightweight'],\n",
    " data['spandex'],\n",
    " data['breathable'],\n",
    " data['loose'],\n",
    " data['loose fit'],\n",
    " data['fitted'],\n",
    " data['core'],\n",
    " data['blend'],\n",
    " data['cotton'],\n",
    " data['high waist'],\n",
    " data['tights'],\n",
    " data['baggy'],\n",
    " data['slim'],\n",
    " data['activewear'],\n",
    " data['sleeveless'],\n",
    " data['active'],\n",
    " data['athletic'],\n",
    " data['relaxed'],\n",
    " data['performance'],\n",
    " data['pockets'],\n",
    " data['drawstring'],\n",
    " data['squat'],\n",
    " data['tummy'],\n",
    " data['movement'],\n",
    " data['skinny'],\n",
    " data['workout'],\n",
    " data['racerback'],\n",
    " data['scoop neck'],\n",
    " data['v neck'],\n",
    " data['raglan'],\n",
    " data['tapered'],\n",
    " data['lined'],\n",
    " data['quick dry'],\n",
    " data['padded'],\n",
    " data['running'],\n",
    " data['ventilated'],\n",
    " data['warm up'],\n",
    " data['crop top'],\n",
    " data['crop hoodie'],\n",
    " data['elastic'],\n",
    " data['dri fit'],\n",
    " data['cropped'],\n",
    " data['wicking'],\n",
    " data['mid rise'],\n",
    " data['active gear'],\n",
    " data['running gear'],\n",
    " data['split back'])\n",
    "print(f\"Results of ANOVA test:\\n The F-statistic is: {fvalue}\\n The p-value is: {pvalue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** Reject the null hypothesis that mean search volume is equal across all athleisure-related keywords.\n",
    "\n",
    "**Conclusion:** Keyword on its own, does indeed constitute a difference in average search volume for athleisure-related items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tukey Test\n",
    " - We run the Tukey test to examine individual between specific groups, or keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "# perform multiple pairwise comparison (Tukey HSD)\n",
    "m_comp = pairwise_tukeyhsd(endog=athleisure_df['volume'], groups=athleisure_df['keyword'], alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flatironschooldc2/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "tukey_data = pd.DataFrame(data=m_comp._results_table.data[1:], columns = m_comp._results_table.data[0])\n",
    "\n",
    "group1_comp =tukey_data.loc[tukey_data.reject == True].groupby('group1').reject.count()\n",
    "group2_comp = tukey_data.loc[tukey_data.reject == True].groupby('group2').reject.count()\n",
    "tukey_data = pd.concat([group1_comp, group2_comp], axis=1)\n",
    "\n",
    "tukey_data = tukey_data.fillna(0)\n",
    "tukey_data.columns = ['reject1', 'reject2']\n",
    "tukey_data['total_sum'] = tukey_data.reject1 + tukey_data.reject2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reject1</th>\n",
       "      <th>reject2</th>\n",
       "      <th>total_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>hoodie</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>running</td>\n",
       "      <td>28.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sweatshirt</td>\n",
       "      <td>11.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>workout</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>flex</td>\n",
       "      <td>33.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3 stripes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spandex</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>muscle tank</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>muscle tee</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pullover</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             reject1  reject2  total_sum\n",
       "hoodie          50.0     25.0       75.0\n",
       "running         28.0     46.0       74.0\n",
       "sweatshirt      11.0     62.0       73.0\n",
       "workout          1.0     70.0       71.0\n",
       "flex            33.0     13.0       46.0\n",
       "3 stripes        5.0      0.0        5.0\n",
       "spandex          2.0      3.0        5.0\n",
       "muscle tank      3.0      2.0        5.0\n",
       "muscle tee       3.0      2.0        5.0\n",
       "pullover         3.0      2.0        5.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tukey_data.sort_values('total_sum',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 terms that are the \"most\" statistically different than the rest are:\n",
    "- **hoodie, running, sweatshirt, workout, flex**  \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Test 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any differences between months when considering search volume?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_{02}$ - People will be equally likely to search for activewear-related terms in any given month.  \n",
    "$H_{A2}$ - People will be more likely to search for activewear-related terms depending on the month.\n",
    "\n",
    "Average Volume(Jan) = Average Volume(Feb) = Average Volume(Mar) = Average Volume(Apr) = Average Volume(May) = Average Volume(Jun) = Average Volume(Jul) = Average Volume(Aug) = Average Volume(Sep) = Average Volume(Oct) = Average Volume(Nov) = Average Volume(Dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(athleisure_df.month_abbr.unique())\n",
    "\n",
    "values = []\n",
    "for month in list(athleisure_df.month_abbr.unique()):\n",
    "    values.append(list(athleisure_df.loc[athleisure_df['month_abbr'] == month, 'volume']))\n",
    "\n",
    "data = dict(zip(keys, values))\n",
    "\n",
    "month_df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of ANOVA test:\n",
      " The F-statistic is: 0.5315732325700696\n",
      " The p-value is: 0.8831258135517717\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "# stats f_oneway functions takes the groups as input and returns F and P-value\n",
    "fvalue, pvalue = stats.f_oneway(month_df['Jan'],\n",
    "                                month_df['Feb'], \n",
    "                                month_df['Mar'], \n",
    "                                month_df['Apr'],\n",
    "                                month_df['May'],\n",
    "                                month_df['Jun'],\n",
    "                                month_df['Jul'],\n",
    "                                month_df['Aug'],\n",
    "                                month_df['Sep'],\n",
    "                                month_df['Oct'],\n",
    "                                month_df['Nov'],\n",
    "                                month_df['Dec'])\n",
    "\n",
    "print(f\"Results of ANOVA test:\\n The F-statistic is: {fvalue}\\n The p-value is: {pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>C(month)</td>\n",
       "      <td>8.591816e+08</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.531573</td>\n",
       "      <td>0.883126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Residual</td>\n",
       "      <td>3.773325e+11</td>\n",
       "      <td>2568.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sum_sq      df         F    PR(>F)\n",
       "C(month)  8.591816e+08    11.0  0.531573  0.883126\n",
       "Residual  3.773325e+11  2568.0       NaN       NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get ANOVA table as R like output\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "# reshape the d dataframe suitable for statsmodels package \n",
    "month_df_melt = pd.melt(month_df.reset_index(), id_vars=['index'], value_vars=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "# replace column names\n",
    "month_df_melt.columns = ['index', 'month', 'volume']\n",
    "# Ordinary Least Squares (OLS) model\n",
    "model = ols('volume ~ C(month)', data=month_df_melt).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Conclusions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** Fail to reject the null hypothesis that mean search volume is equal across all months.\n",
    "\n",
    "**Conclusion:** Month on its own, does not constitute a difference in search volumes for athleisure-related items.  \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "There is no need to run the Tukey multiple comparisons test due to failling to reject the null hypothesis\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Test 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any differences among search engines when considering search volumes?\n",
    "\n",
    "$H_{03}$ - There will be an equal search volume for activewear-related terms on any platform.  \n",
    "$H_{A3}$ - There will be a greater search volume for activewear-related terms on one particular platform.\n",
    "\n",
    "Average Volume(Google) = Average Volume(YouTube) = Average Volume(Amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(athleisure_df.engine.unique())\n",
    "\n",
    "values = []\n",
    "for engine in list(athleisure_df.engine.unique()):\n",
    "    values.append(list(athleisure_df.loc[athleisure_df['engine'] == engine, 'volume']))\n",
    "\n",
    "data = dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of ANOVA test:\n",
      " The F-statistic is: 40.08443136373594\n",
      " The p-value is: 7.19196465389629e-18\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "# stats f_oneway functions takes the groups as input and returns F and P-value\n",
    "fvalue, pvalue = stats.f_oneway(data['google'],\n",
    "                                data['youtube'], \n",
    "                                data['amazon'])\n",
    "\n",
    "print(f\"Results of ANOVA test:\\n The F-statistic is: {fvalue}\\n The p-value is: {pvalue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** Reject the null hypothesis that mean search volume is equal across all search engines.\n",
    "\n",
    "**Conclusion:** Search engine on its own, does indeed constitute a difference in average search volume for athleisure-related items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tukey Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Multiple Comparison of Means - Tukey HSD, FWER=0.05     \n",
      "============================================================\n",
      "group1  group2  meandiff p-adj    lower      upper    reject\n",
      "------------------------------------------------------------\n",
      "amazon  google -3527.733  0.001 -4851.7536 -2203.7124   True\n",
      "amazon youtube 1442.6709 0.0373    66.3663  2818.9755   True\n",
      "google youtube 4970.4039  0.001   3615.639  6325.1687   True\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "# perform multiple pairwise comparison (Tukey HSD)\n",
    "m_comp = pairwise_tukeyhsd(endog=athleisure_df['volume'], groups=athleisure_df['engine'], alpha=0.05)\n",
    "print(m_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** In all cases, reject the null hypothesis that search engine 1 is equal to search engine 2 in terms of average search volume.\n",
    "\n",
    "**Conclusion:** Search volumes are unique to each platform.  \n",
    "<br>\n",
    "\n",
    "Arranging by mean difference: YouTube > Amazon > Google\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 2-Factor ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we determine which specific 2-factor combinations of keyword/month/search engine generate the highest search volume?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_{01}$ - All keyword/engine combinations are equal in terms of mean search volume.  \n",
    "$H_{A1}$ - Some keyword/engine combinations have greater mean search volume.\n",
    "\n",
    "\n",
    "\n",
    "$H_{02}$ - All keyword/month combinations are equal in terms of mean search volume.  \n",
    "$H_{A2}$ - Some keyword/month combinations have greater mean search volume.\n",
    "\n",
    "\n",
    "$H_{03}$ - All engine/month combinations are equal in terms of mean search volume.  \n",
    "$H_{A3}$ - Some engine/month combinations have greater mean search volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_df = athleisure_df.loc[:,['volume','keyword','engine','month_abbr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flatironschooldc2/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/statsmodels/base/model.py:1752: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 76, but rank is 61\n",
      "  'rank is %d' % (J, J_), ValueWarning)\n",
      "/Users/flatironschooldc2/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/statsmodels/base/model.py:1752: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 152, but rank is 141\n",
      "  'rank is %d' % (J, J_), ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                sum_sq      df          F         PR(>F)\n",
      "C(keyword)                1.021546e+11    76.0  19.630897  9.219712e-149\n",
      "C(engine)                 1.072592e+10     2.0  78.324956   4.462158e-33\n",
      "C(month_abbr)             8.591816e+08    11.0   1.140743   3.249134e-01\n",
      "C(keyword):C(engine)      1.156474e+11   152.0  11.111892  1.008919e-151\n",
      "C(keyword):C(month_abbr)  5.446891e+10   836.0   0.951564   7.896266e-01\n",
      "C(engine):C(month_abbr)   1.143128e+09    22.0   0.758871   7.789742e-01\n",
      "Residual                  1.024321e+11  1496.0        NaN            NaN\n"
     ]
    }
   ],
   "source": [
    "# ANOVA results with combinations of 2 groups:\n",
    "formula = 'volume ~ C(keyword) + C(engine) + C(month_abbr) + C(keyword):C(engine) + C(keyword):C(month_abbr) + C(engine):C(month_abbr)'\n",
    "lm = ols(formula, anova_df).fit()\n",
    "table = sm.stats.anova_lm(lm, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "- Reject the null hypothesis that the mean search volume is equal among all Keyword/Engine combinations\n",
    "- Fail to reject the null hypothesis that the mean search volume is equal among all Keyword/Month and Engine/Month combinations  \n",
    "\n",
    "**Conclusion:**\n",
    "- Keyword/Engine combinations mean search volumes are statistically different from each other\n",
    "- Keyword/Month and Engine/Month are not statistically different from each other\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tukey Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_df['combination'] = anova_df.keyword + \" / \" + anova_df.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "# perform multiple pairwise comparison (Tukey HSD)\n",
    "m_comp = pairwise_tukeyhsd(endog=anova_df['volume'], groups=anova_df['combination'], alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flatironschooldc2/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reject1</th>\n",
       "      <th>reject2</th>\n",
       "      <th>total_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>running / youtube</td>\n",
       "      <td>85.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hoodie / youtube</td>\n",
       "      <td>142.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sweatshirt / youtube</td>\n",
       "      <td>35.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>workout / amazon</td>\n",
       "      <td>4.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>flex / youtube</td>\n",
       "      <td>148.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hoodie / amazon</td>\n",
       "      <td>141.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>leggings / amazon</td>\n",
       "      <td>127.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>workout / youtube</td>\n",
       "      <td>2.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>joggers / amazon</td>\n",
       "      <td>126.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cotton / youtube</td>\n",
       "      <td>155.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3 stripes / google</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>skinny / amazon</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>scoop neck / youtube</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>short sleeve / google</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>short sleeve / youtube</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sleeveless / amazon</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>skinny / google</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>scoop neck / amazon</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sleeveless / google</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>slim / google</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        reject1  reject2  total_sum\n",
       "running / youtube          85.0    128.0      213.0\n",
       "hoodie / youtube          142.0     71.0      213.0\n",
       "sweatshirt / youtube       35.0    177.0      212.0\n",
       "workout / amazon            4.0    206.0      210.0\n",
       "flex / youtube            148.0     60.0      208.0\n",
       "hoodie / amazon           141.0     67.0      208.0\n",
       "leggings / amazon         127.0     67.0      194.0\n",
       "workout / youtube           2.0    191.0      193.0\n",
       "joggers / amazon          126.0     63.0      189.0\n",
       "cotton / youtube          155.0     28.0      183.0\n",
       "3 stripes / google         10.0      0.0       10.0\n",
       "skinny / amazon             3.0      7.0       10.0\n",
       "scoop neck / youtube        3.0      7.0       10.0\n",
       "short sleeve / google       3.0      7.0       10.0\n",
       "short sleeve / youtube      3.0      7.0       10.0\n",
       "sleeveless / amazon         3.0      7.0       10.0\n",
       "skinny / google             3.0      7.0       10.0\n",
       "scoop neck / amazon         3.0      7.0       10.0\n",
       "sleeveless / google         3.0      7.0       10.0\n",
       "slim / google               3.0      7.0       10.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tukey_data = pd.DataFrame(data=m_comp._results_table.data[1:], columns = m_comp._results_table.data[0])\n",
    "\n",
    "group1_comp =tukey_data.loc[tukey_data.reject == True].groupby('group1').reject.count()\n",
    "group2_comp = tukey_data.loc[tukey_data.reject == True].groupby('group2').reject.count()\n",
    "tukey_data = pd.concat([group1_comp, group2_comp], axis=1)\n",
    "\n",
    "tukey_data = tukey_data.fillna(0)\n",
    "tukey_data.columns = ['reject1', 'reject2']\n",
    "tukey_data['total_sum'] = tukey_data.reject1 + tukey_data.reject2\n",
    "\n",
    "tukey_data.sort_values('total_sum',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 Keyword/Engine combinations that are significantly different in search volume than the rest of the combinations:  \n",
    "\n",
    "**running / youtube**  \n",
    "**hoodie / youtube**  \n",
    "**sweatshirt / youtube**   \n",
    "**workout / amazon**  \n",
    "**flex / youtube**  \n",
    "**hoodie / amazon**  \n",
    "**leggings / amazon**    \n",
    "**workout / youtube**  \n",
    "**joggers / amazon**  \n",
    "**cotton / youtube**  \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 3-Factor ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_df['combination2'] = anova_df.keyword + \" / \" + anova_df.month_abbr + \" / \" + anova_df.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cannot run below due to lack of processing power**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-fdd4acbb9069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mformula\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'volume ~ C(keyword) + C(engine) + C(month_abbr) + C(keyword):C(engine) + C(keyword):C(month_abbr) + C(engine):C(month_abbr) + C(engine):C(month_abbr):C(keyword)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manova_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manova_lm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/statsmodels/stats/anova.py\u001b[0m in \u001b[0;36manova_lm\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0manova_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/statsmodels/stats/anova.py\u001b[0m in \u001b[0;36manova_single\u001b[0;34m(model, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"II\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         return anova2_lm_single(model, design_info, n_rows, test, pr_test,\n\u001b[0;32m---> 83\u001b[0;31m                                 robust)\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"III\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         return anova3_lm_single(model, design_info, n_rows, test, pr_test,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/statsmodels/stats/anova.py\u001b[0m in \u001b[0;36manova2_lm_single\u001b[0;34m(model, design_info, n_rows, test, pr_test, robust)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mLVL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrobust_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0morth_compl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLVL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mL2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;31m# L1|2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/scipy/linalg/decomp_qr.py\u001b[0m in \u001b[0;36mqr\u001b[0;34m(a, overwrite_a, lwork, mode, pivoting, check_finite)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_chkfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AllFloat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         raise ValueError(\n\u001b[0;32m--> 498\u001b[0;31m             \"array must not contain infs or NaNs\")\n\u001b[0m\u001b[1;32m    499\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "# ANOVA results with combinations of 2 groups:\n",
    "formula = 'volume ~ C(keyword) + C(engine) + C(month_abbr) + C(keyword):C(engine) + C(keyword):C(month_abbr) + C(engine):C(month_abbr) + C(engine):C(month_abbr):C(keyword)'\n",
    "lm = ols(formula, anova_df).fit()\n",
    "table = sm.stats.anova_lm(lm, typ=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "# perform multiple pairwise comparison (Tukey HSD)\n",
    "m_comp = pairwise_tukeyhsd(endog=anova_df['volume'], groups=anova_df['combination2'], alpha=0.05)\n",
    "print(m_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tukey_data = pd.DataFrame(data=m_comp._results_table.data[1:], columns = m_comp._results_table.data[0])\n",
    "\n",
    "group1_comp =tukey_data.loc[tukey_data.reject == True].groupby('group1').reject.count()\n",
    "group2_comp = tukey_data.loc[tukey_data.reject == True].groupby('group2').reject.count()\n",
    "tukey_data = pd.concat([group1_comp, group2_comp], axis=1)\n",
    "\n",
    "tukey_data = tukey_data.fillna(0)\n",
    "tukey_data.columns = ['reject1', 'reject2']\n",
    "tukey_data['total_sum'] = tukey_data.reject1 + tukey_data.reject2\n",
    "\n",
    "tukey_data.sort_values('total_sum',ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
