{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Chi-Squared-Goodness-Of-Fit-Test\" data-toc-modified-id=\"Chi-Squared-Goodness-Of-Fit-Test-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Chi-Squared Goodness-Of-Fit Test</a></span></li><li><span><a href=\"#Chi-Squared-Test-of-Independence\" data-toc-modified-id=\"Chi-Squared-Test-of-Independence-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Chi-Squared Test of Independence</a></span></li><li><span><a href=\"#sklearn-feature-selection-chi2\" data-toc-modified-id=\"sklearn-feature-selection-chi2-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>sklearn feature selection chi2</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-Squared Goodness-Of-Fit Test\n",
    "Ref: http://hamelg.blogspot.com/2015/11/python-for-data-analysis-part-25-chi.html\n",
    "\n",
    "In our study of t-tests, we introduced the one-way t-test to check whether a sample mean differs from the an expected (population) mean. The chi-squared goodness-of-fit test is an analog of the one-way t-test for categorical variables: it tests whether the distribution of sample categorical data matches an expected distribution. For example, you could use a chi-squared goodness-of-fit test to check whether the race demographics of members at your church or school match that of the entire U.S. population or whether the computer browser preferences of your friends match those of Internet uses as a whole.\n",
    "When working with categorical data, the values themselves aren't of much use for statistical testing because categories like \"male\", \"female,\" and \"other\" have no mathematical meaning. Tests dealing with categorical variables are based on variable counts instead of the actual value of the variables themselves.\n",
    "Let's generate some fake demographic data for U.S. and Minnesota and walk through the chi-square goodness of fit test to check whether they are different:\n",
    "\n",
    "\n",
    "$\\chi_{c}^{2}=\\sum \\frac{\\left(O_{i}-E_{i}\\right)^{2}}{E_{i}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:39:01.903990Z",
     "start_time": "2020-09-24T16:39:00.384238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statsmodels 0.12.0\n",
      "seaborn     0.11.0\n",
      "scipy       1.4.1\n",
      "numpy       1.18.4\n",
      "pandas      1.1.0\n",
      "json        2.0.9\n",
      "autopep8    1.5.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os,sys,time\n",
    "import scipy\n",
    "import statsmodels\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import ttest_ind # independent means two samples.\n",
    "from statsmodels.stats import weightstats as stests # stests.ztest\n",
    "\n",
    "SEED = 100\n",
    "pd.set_option('max_columns',100)\n",
    "pd.set_option('plotting.backend','plotly') # matplotlib, bokeh, altair, plotly\n",
    "%load_ext watermark\n",
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:39:02.000890Z",
     "start_time": "2020-09-24T16:39:01.906572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National\n",
      "col_0      count\n",
      "0               \n",
      "asian      15000\n",
      "black      50000\n",
      "hispanic   60000\n",
      "other      35000\n",
      "white     100000\n",
      " \n",
      "Minnesota\n",
      "col_0     count\n",
      "0              \n",
      "asian        75\n",
      "black       250\n",
      "hispanic    300\n",
      "other       150\n",
      "white       600\n"
     ]
    }
   ],
   "source": [
    "national = pd.DataFrame([\"white\"]*100000 + [\"hispanic\"]*60000 +\\\n",
    "                        [\"black\"]*50000 + [\"asian\"]*15000 + [\"other\"]*35000)\n",
    "           \n",
    "\n",
    "minnesota = pd.DataFrame([\"white\"]*600 + [\"hispanic\"]*300 + \\\n",
    "                         [\"black\"]*250 +[\"asian\"]*75 + [\"other\"]*150)\n",
    "\n",
    "national_table = pd.crosstab(index=national[0], columns=\"count\")\n",
    "minnesota_table = pd.crosstab(index=minnesota[0], columns=\"count\")\n",
    "\n",
    "print( \"National\")\n",
    "print(national_table)\n",
    "print(\" \")\n",
    "print( \"Minnesota\")\n",
    "print(minnesota_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:39:02.012065Z",
     "start_time": "2020-09-24T16:39:02.003681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0\n",
      "count    18.194805\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "observed = minnesota_table\n",
    "\n",
    "national_ratios = national_table/len(national)  # Get population ratios\n",
    "\n",
    "expected = national_ratios * len(minnesota)   # Get expected counts\n",
    "\n",
    "chi_squared_stat = (((observed-expected)**2)/expected).sum()\n",
    "\n",
    "print(chi_squared_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: The chi-squared test assumes none of the expected counts are less than 5.\n",
    "Similar to the t-test where we compared the t-test statistic to a critical value based on the t-distribution to determine whether the result is significant, in the chi-square test we compare the chi-square test statistic to a critical value based on the chi-square distribution. The scipy library shorthand for the chi-square distribution is chi2. Let's use this knowledge to find the critical value for 95% confidence level and check the p-value of our result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:39:02.027945Z",
     "start_time": "2020-09-24T16:39:02.014803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical value\n",
      "9.487729036781154\n",
      "P value\n",
      "[0.00113047]\n"
     ]
    }
   ],
   "source": [
    "crit = stats.chi2.ppf(q = 0.95, # Find the critical value for 95% confidence*\n",
    "                      df = 4)   # Df = number of variable categories - 1\n",
    "\n",
    "print(\"Critical value\")\n",
    "print(crit)\n",
    "\n",
    "p_value = 1 - stats.chi2.cdf(x=chi_squared_stat,  # Find the p-value\n",
    "                             df=4)\n",
    "print(\"P value\")\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: we are only interested in the right tail of the chi-square distribution.\n",
    "Since our chi-squared statistic exceeds the critical value, we'd reject the null hypothesis that the two distributions are the same.\n",
    "You can carry out a chi-squared goodness-of-fit test automatically using the scipy function scipy.stats.chisquare():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:39:02.044963Z",
     "start_time": "2020-09-24T16:39:02.036776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=array([18.19480519]), pvalue=array([0.00113047]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chisquare(f_obs= observed,   # Array of observed counts\n",
    "                f_exp= expected)   # Array of expected counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-Squared Test of Independence\n",
    "Independence is a key concept in probability that describes a situation where knowing the value of one variable tells you nothing about the value of another. For instance, the month you were born probably doesn't tell you anything about which web browser you use, so we'd expect birth month and browser preference to be independent. On the other hand, your month of birth might be related to whether you excelled at sports in school, so month of birth and sports performance might not be independent.\n",
    "The chi-squared test of independence tests whether two categorical variables are independent. The test of independence is commonly used to determine whether variables like education, political views and other preferences vary based on demographic factors like gender, race and religion. Let's generate some fake voter polling data and perform a test of independence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:39:02.125829Z",
     "start_time": "2020-09-24T16:39:02.051438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>democrat</th>\n",
       "      <th>independent</th>\n",
       "      <th>republican</th>\n",
       "      <th>row_totals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>asian</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>65</td>\n",
       "      <td>25</td>\n",
       "      <td>64</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hispanic</th>\n",
       "      <td>107</td>\n",
       "      <td>50</td>\n",
       "      <td>94</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>189</td>\n",
       "      <td>96</td>\n",
       "      <td>212</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_totals</th>\n",
       "      <td>397</td>\n",
       "      <td>186</td>\n",
       "      <td>417</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            democrat  independent  republican  row_totals\n",
       "asian             21            7          32          60\n",
       "black             65           25          64         154\n",
       "hispanic         107           50          94         251\n",
       "other             15            8          15          38\n",
       "white            189           96         212         497\n",
       "col_totals       397          186         417        1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "# Sample data randomly at fixed probabilities\n",
    "voter_race = np.random.choice(a= [\"asian\",\"black\",\"hispanic\",\"other\",\"white\"],\n",
    "                              p = [0.05, 0.15 ,0.25, 0.05, 0.5],\n",
    "                              size=1000)\n",
    "\n",
    "# Sample data randomly at fixed probabilities\n",
    "voter_party = np.random.choice(a= [\"democrat\",\"independent\",\"republican\"],\n",
    "                              p = [0.4, 0.2, 0.4],\n",
    "                              size=1000)\n",
    "\n",
    "voters = pd.DataFrame({\"race\":voter_race, \n",
    "                       \"party\":voter_party})\n",
    "\n",
    "voter_tab = pd.crosstab(voters.race, voters.party, margins = True)\n",
    "\n",
    "voter_tab.columns = [\"democrat\",\"independent\",\"republican\",\"row_totals\"]\n",
    "\n",
    "voter_tab.index = [\"asian\",\"black\",\"hispanic\",\"other\",\"white\",\"col_totals\"]\n",
    "\n",
    "observed = voter_tab.iloc[:-1,:-1]   # Get table without totals for later use\n",
    "voter_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:39:02.135203Z",
     "start_time": "2020-09-24T16:39:02.129307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.82"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to calculate expected value?\n",
    "# look at race=asian and party=democrate   i.e. value = 21\n",
    "# out of 1000 population, for asian democrat we consider only population 60*397/1000\n",
    "\n",
    "# myexpected = (col_total * row_total) / whole_total\n",
    "myexpected = 397 * 60/1000\n",
    "myexpected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the expected count for a cell, multiply the row total for that cell by the column total for that cell and then divide by the total number of observations. We can quickly get the expected counts for all cells in the table by taking the row totals and column totals of the table, performing an outer product on them with the np.outer() function and dividing by the number of observations.\n",
    "\n",
    "For two arrays of lengths m,n, the  np.outer(arr1,arr2) it gives matrix of shape m,n\n",
    "with corrosponding products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:39:02.158938Z",
     "start_time": "2020-09-24T16:39:02.138766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>democrat</th>\n",
       "      <th>independent</th>\n",
       "      <th>republican</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>asian</th>\n",
       "      <td>23.820</td>\n",
       "      <td>11.160</td>\n",
       "      <td>25.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>61.138</td>\n",
       "      <td>28.644</td>\n",
       "      <td>64.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hispanic</th>\n",
       "      <td>99.647</td>\n",
       "      <td>46.686</td>\n",
       "      <td>104.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>15.086</td>\n",
       "      <td>7.068</td>\n",
       "      <td>15.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>197.309</td>\n",
       "      <td>92.442</td>\n",
       "      <td>207.249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          democrat  independent  republican\n",
       "asian       23.820       11.160      25.020\n",
       "black       61.138       28.644      64.218\n",
       "hispanic    99.647       46.686     104.667\n",
       "other       15.086        7.068      15.846\n",
       "white      197.309       92.442     207.249"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 1000\n",
    "row_totals = voter_tab[\"row_totals\"][:-1]\n",
    "col_totals = voter_tab.loc[\"col_totals\"][:-1]\n",
    "\n",
    "expected =  np.outer(row_totals, col_totals) / total\n",
    "\n",
    "expected = pd.DataFrame(expected)\n",
    "\n",
    "expected.columns = [\"democrat\",\"independent\",\"republican\"]\n",
    "expected.index = [\"asian\",\"black\",\"hispanic\",\"other\",\"white\"]\n",
    "\n",
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:39:02.169672Z",
     "start_time": "2020-09-24T16:39:02.162949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dof=8\n",
      "expected values=\n",
      " [[ 23.82   11.16   25.02 ]\n",
      " [ 61.138  28.644  64.218]\n",
      " [ 99.647  46.686 104.667]\n",
      " [ 15.086   7.068  15.846]\n",
      " [197.309  92.442 207.249]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# another way\n",
    "contingency_table = observed.to_numpy()\n",
    "stat, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "print('dof=%d' % dof)\n",
    "print('expected values=\\n',expected)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:39:02.179682Z",
     "start_time": "2020-09-24T16:39:02.173365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.169321280162059\n"
     ]
    }
   ],
   "source": [
    "chi_squared_stat = (((observed-expected)**2)/expected).sum().sum()\n",
    "print(chi_squared_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:39:02.197465Z",
     "start_time": "2020-09-24T16:39:02.188324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical value\n",
      "15.50731305586545\n",
      "P value\n",
      "0.518479392948842\n"
     ]
    }
   ],
   "source": [
    "nrows, ncols = observed.shape\n",
    "ddof = (nrows-1) * (ncols-1)\n",
    "crit = stats.chi2.ppf(q = 0.95, df = ddof) \n",
    "\n",
    "print(\"Critical value\")\n",
    "print(crit)\n",
    "\n",
    "p_value = 1 - stats.chi2.cdf(x=chi_squared_stat,df=ddof)\n",
    "print(\"P value\")\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: The degrees of freedom for a test of independence equals the product of the number of categories in each variable minus 1. In this case we have a 5x3 table so df = 4x2 = 8.\n",
    "As with the goodness-of-fit test, we can use scipy to conduct a test of independence quickly. Use stats.chi2_contingency() function to conduct a test of independence automatically given a frequency table of observed counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:39:02.210306Z",
     "start_time": "2020-09-24T16:39:02.200853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.169321280162059,\n",
       " 0.518479392948842,\n",
       " 8,\n",
       " array([[ 23.82 ,  11.16 ,  25.02 ],\n",
       "        [ 61.138,  28.644,  64.218],\n",
       "        [ 99.647,  46.686, 104.667],\n",
       "        [ 15.086,   7.068,  15.846],\n",
       "        [197.309,  92.442, 207.249]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chi2_contingency(observed= observed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows the chi-square statistic, the p-value and the degrees of freedom followed by the expected counts.\n",
    "As expected, given the high p-value, the test result does not detect a significant relationship between the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn feature selection chi2\n",
    "\n",
    "References\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html  \n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html  \n",
    "- https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection\n",
    "\n",
    "Compute chi-squared stats between each non-negative feature and class.\n",
    "\n",
    "This score can be used to select the n_features features with the highest values for the test chi-squared statistic from X, which must contain only non-negative features such as booleans or frequencies (e.g., term counts in document classification), relative to the classes.\n",
    "\n",
    "Recall that the chi-square test measures dependence between stochastic variables, so using this function “weeds out” the features that are the most likely to be independent of class and therefore irrelevant for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:45:45.283377Z",
     "start_time": "2020-09-24T16:45:45.276249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (10, 5)\n",
      "y sahpe: (10,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 0, 0, 0, 1],\n",
    "       [1, 1, 0, 1, 1],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 1],\n",
    "       [1, 0, 0, 0, 1],\n",
    "       [1, 0, 1, 1, 1],\n",
    "       [0, 1, 1, 0, 0],\n",
    "       [1, 0, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 0]])\n",
    "y = np.array([1, 0, 0, 0, 1, 1, 1, 1, 0, 1])\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y sahpe: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:43:32.349572Z",
     "start_time": "2020-09-24T16:43:32.341042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1, 1, 2, 2],\n",
       "       [4, 2, 3, 2, 4]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.vstack([1 - y, y])\n",
    "observed = np.dot(Y, X)\n",
    "observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:43:42.195165Z",
     "start_time": "2020-09-24T16:43:42.176909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.8, 1.2, 1.6, 1.6, 2.4],\n",
       "       [4.2, 1.8, 2.4, 2.4, 3.6]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_count = X.sum(axis=0)\n",
    "class_prob = Y.mean(axis=1)\n",
    "expected = np.dot(feature_count.reshape(-1, 1), class_prob.reshape(1, -1)).T\n",
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:43:54.345227Z",
     "start_time": "2020-09-24T16:43:54.339108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02380952, 0.05555556, 0.375     , 0.16666667, 0.11111111])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "score, pval = chisquare(observed, expected)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:43:57.068646Z",
     "start_time": "2020-09-24T16:43:57.064106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87737056, 0.81366372, 0.54029137, 0.6830914 , 0.73888268])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:46:43.080779Z",
     "start_time": "2020-09-24T16:46:43.078189Z"
    }
   },
   "outputs": [],
   "source": [
    "## sklearn example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T16:48:54.264867Z",
     "start_time": "2020-09-24T16:48:54.255600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old shape: (150, 4)\n",
      "New shape: (150, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "print(f\"old shape: {X.shape}\")\n",
    "\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "print(f\"New shape: {X_new.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dataSc)",
   "language": "python",
   "name": "datasc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
